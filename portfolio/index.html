<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/katex/katex.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,400italic|Source+Code+Pro:400,700" type="text/css"> <link rel=stylesheet  href="/css/font-awesome.min.css"> <link rel=stylesheet  href="/css/celeste.min.css"> <link rel=apple-touch-icon  sizes=180x180  href="/apple-touch-icon.png"> <link rel=icon  type="image/png" sizes=32x32  href="/favicon-32x32.png"> <link rel=icon  type="image/png" sizes=16x16  href="/favicon-16x16.png"> <link rel=manifest  href="/site.webmanifest"> <title>Data Science Portfolio</title> <header> <nav class=nav-main > <ul> <li class=hvr-underline-reveal ><a href="/">ABOUT</a> <li class=hvr-underline-reveal ><a href="/research/">RESEARCH</a> <li class=logo ><a class=hvr-ripple-out  href="/">JR</a> <li class=hvr-underline-reveal ><a href="/teaching/">TEACHING</a> <li class=hvr-underline-reveal ><a href="/portfolio/">PORTFOLIO</a> </ul> </nav> </header> <div class=franklin-content > <h1 id=machine_learning ><a href="#machine_learning" class=header-anchor >MACHINE LEARNING</a></h1> <h2 id=does_online_courses_attract_students ><a href="#does_online_courses_attract_students" class=header-anchor >Does Online Courses Attract Students?</a></h2> <h4 id=9_september_2023_last_updated_26_september_2023 ><a href="#9_september_2023_last_updated_26_september_2023" class=header-anchor >9 September 2023 &#40;Last Updated: 26 September 2023&#41;</a></h4> <div align = "justify"> (The associated codes and implementations in this project is located in the Jupyter <a href = "/assets/enrollment.ipynb">notebook</a>.) </div> <div align = "justify"> <h3>Background and Objective</h3> You are working as a data scientist at a local University. The university started offering online courses to reach a wider range of students. The university wants you to help them understand enrollment trends. They would like you to identify what contributes to higher enrollment. In particular, whether the <b>course type</b> (online or classroom) is a factor. </div> <div align = "justify"> <h3>Executive Summary</h3> To determine whether course type is a factor in enrollment, we analyze the enrollment counts and test our hypotheses. Furthermore, we provide a machine learning model to predict enrollment counts of future offered courses by the university. The report is divided into the following sections: <ol> <li>Introduction: Overview of enrollment trends in universities offering both online and onsite courses. <li>Data Preprocessing: Detailed explanation on data cleaning. <li>Hypothesis Testing: Test to determine whether difference in enrollment counts is significant. <li>Regression Model: Model to predict future enrollment trends. </ol> </div> <div align = "justify"> <h3>Introduction</h3> Enrollment trends in online courses accelerated dramatically during the COVID-19 pandemic. During the height of the pandemic, most classes moved to online-only instruction. While the effects of the pandemic has subsided, online learning remains popular, with many students choosing to take online courses or even complete entire degrees online. In hindsight, online courses offer flexibility and convenience that traditional classroom-based courses cannot. Students can take online courses at their own pace and on their own schedule, from anywhere in the world. This makes online learning a good option for students who are working full-time, have families, or live in remote areas. However, there are also some drawbacks such as the difficulty of staying motivated and engaged. Students also miss out on the social interaction and networking opportunities that are available in traditional classroom settings. It is important to note that online and onsite learning are not mutually exclusive. Many students choose to take a mix of online and onsite courses. This allows them to take advantage of the benefits of both types of learning. </div> <div align = "justify"> <h3>Data Preprocessing</h3> First, we import the data and clean the data using methods and functions available in the <code>pandas</code> library. For every column, we shall do the following: <ol> <li> Check the number of missing values. <li> Check the values whether they match the appropriate description (or data type). </ol> The <code>pandas</code> are imported using the alias <code>pd</code>. The <code>.read_csv</code> method imports the <a href = "https://s3.amazonaws.com/talent-assets.datacamp.com/university_enrollment_2306.csv"> dataset </a>. The <code>.head</code> method allows observation of the first few specified rows of the pandas dataframe. </div> <br> <table> <tr> <th>course_id <th>course_type <th>year <th>enrollment_count <th>pre_score <th>post_score <th>pre_requirement <th>department <tr> <td>1 <td>classroom <td>2018 <td>165 <td>28.14 <td>73.0 <td>Beginner <td>Science <tr> <td>2 <td>classroom <td>2020 <td>175 <td>79.68 <td>86.0 <td>None <td>Science <tr> <td>1 <td>classroom <td>2018 <td>165 <td>28.14 <td>73.0 <td>Beginner <td>Science <tr> <td>3 <td>online <td>2016 <td>257 <td>57.24 <td>80.0 <td>NaN <td>Mathematics <tr> <td>4 <td>online <td>2013 <td>251 <td>97.67 <td>75.0 <td>Beginner <td>Technology </table> <div align = "justify"> Using the <code>.info</code> method, the data types of the features are as follows: <ul> <li><code>course_type</code>: integer <li><code>year</code>: integer <li><code>enrollment_count</code>: string <li><code>pre_score</code>: string <li><code>post_score</code>: floating-point number <li><code>pre_requirement</code>: string <li><code>department</code>: string </ul> For the missing values, the <code>post_score</code> and <code>pre_requirement</code> columns have 185 and 89 missing values respectively. These values are obtained using the <code>.isna</code> and <code>.sum</code> methods. <br> Now, we correct the data types and fill-in the missing values. The missing scores are assumed to be equal to zero (0) while the missing pre-requisitees are assumed to be empty or <code>'None'</code>. Note that some values of the pre-scores are marked as a dash. We also replace these values as 0. Afterwards, the <code>pre_score</code> column is converted as a list of floating-point numbers, similar to the <code>post_score</code>, using the <code>.astype</code> method. Lastly, the <code>'Math'</code> and <code>'Mathematics'</code> values both exist in the department column. To ensure consistency, <code>'Math'</code> values are replaced by <code>'Mathematics'</code>. <br> The course ID column contain unique values. This means that the number of courses is one-thousand eight hundred fifty (1850). Using the <code>.value_counts</code> method, one thousand three hundred seventy-five (1375) are online while four hundred seventy-five (475) are classroom-based. <br> To provide an overview of the number of courses of each type, refer to the countplot shown below. Online courses are dominant for both the departments and the university. The Technology department offered the most online courses. For succeeding visualization, we shall mainly use the Seaborn package. </div> <br> <div align = "center"> <img src = "/assets/enrollment_bar.png" align=top  width="90%"> </div> <div align = "justify"> <h3>Hypothesis Testing</h3> Recall that we intend to compare the difference between the enrollment counts in each type of course. To start with the hypothesis testing, first observe the the distribution of the enrollment counts. Many courses attracts more than two-hundred fifty (250) enrollees. Moreover, no courses are enrolled with more than two hundred (200) or greater than two hundred twenty (220) students. Lastly, the t-test is not advised to utilize since the enrollment counts are not normally distributed. </div> <br> <div align=center > <img src="/assets/hist_enrol.png" align=top  width="90%"> </div> <br> <div align = "justify"> We provide more insights about the enrollment. Consider the boxplot showing the enrollment counts across the course types. Students tend to enroll more in online courses than in classroom-taught courses. The range and the median of enrollment counts for online courses are farther and greater than that of the classroom-taught courses. As a remark, no anomalies in the enrollment counts are present for both course types. </div> <br> <div align=center > <img src="/assets/box_enrol.png" align=top  width="90%"> </div> <br> <div align=justify > We proceed with the hypothesis testing using a Mann-Whitney U Test. This test is a non-parametric version of the t-test suitable for non-normally distributed data. For implementation in Python, the <code>mannwhitneyu</code> function is imported in the <code>scipy.stats</code> library. By index slicing, the enrollment counts of classroom-based courses is separated from that of the online courses. We choose a significance value of 0.01 and a null hypothesis stating that there is no significant difference between the course type. A p-value of a power of negative two hundred thirty-six (-236) is obtained. Thus, the null hypothesis is rejected and say that there is a significant difference between the course type in the enrollment. </div> <br> <div align = "justify"> The university wants to predict how many students will enroll in a course. This is a regression type of machine learning where the target variable is the enrollment count. For a baseline model, we shall implement a simple Linear Regression model using the scikit-learn library. For the categorical variables, we use the <code>get_dummies</code> method of <code>pandas</code>. For a comparison model, we shall implement an Elastic Net model. We choose the hyperparameter <code>alpha</code> to be equal to <code>0.0001</code>. </div> <br> <div align = "justify"> We considered linear regression as a baseline model due to its simplicity and efficiency in computing. Linear regression provides a linear estimate of the relationship between the independent and the dependent variables. Moreover, the model is robust to overfitting. The loss function for the linear regression model is the ordinary least squares. In elastic net models, a loss function that puts more weight on errors is utilized. Although more complex and requires more tuning, an elastic net model is less prone to overfitting and able to select important features and handle correlated features. </div> <br> <div align = "justify"> We compare the root mean squared errors (RMSE) of the two models. The RMSE for the baseline model is 0.561153419986678 while the RMSE for the Comparison Model is 0.5600931357111498. The RMSE scores are equal up to the second decimal place. Thus, we conclude that the two models perform equally the same. </div> <h2 id=bike_sharing_demand_in_south_korea ><a href="#bike_sharing_demand_in_south_korea" class=header-anchor >Bike Sharing Demand in South Korea</a></h2> <h4 id=20_september_2023 ><a href="#20_september_2023" class=header-anchor >20 September 2023</a></h4> (The associated codes in this project is located in the Jupyter <a href = "/assets/bike_korea.ipynb">notebook</a>.) <div align = "justify"> The dataset consists of the number of public bikes rented in Seoul's bike sharing system at each hour. It also includes information about the weather and the time, such as whether it was a public holiday. </div> <br> <div align = "justify"> For data preprocessing, the column names of the dataset needs renaming as some are lengthy. For instance, the 'Dew point temperature(C)' column name is renamed as 'Dew Temp' and the 'Solar Radiation (MJ/m2)' column name is renamed as 'Solar Rad'. The dataset contains no missing values with six columns of floating point numbers, four columns of signed 64-bit integers, and four columns of string datatypes. </div> <br> <div align = "justify"> Observe the barplot shown below. Summer is the season where most bikes are rented. Also, a non-holiday has a slightly better number of rented bikes compared to a holiday. The same observation holds for if the hours are considered instead of seasons. In this setting, bikes rented are high during the late afternoon to early evening hours than any other time window. </div> <br> <div align = "center"> <img src = "/assets/bike_bar.png"> <img src = "/assets/bike_line.png"> </div> <br> <div align = "justify"> Temperature and dew point temperatures are the highly correlated features in the dataset. A principal component analysis helps mitigate correlation. Note that decision tree-based models are immune to multicollinearity. </div> <div align = "center"> <img src = "/assets/bike_corr.png"> </div> <div align = "justify"> Now, we proceed to the machine learning (ML) model. ML requires numerical values for training a model. One-hot encoding is a way to turn variables from categorical into numerical. We use a decision tree to predict the number of bikes rented. The coefficient of determination score is 0.79. We also utilize a model made up of multiple decision trees. This model is called a Random Forest model. The coefficient of determination score is slightly better than the previous model. For predictions, we can use this model instead. The model considers the hour and the temperature a person rents a bike as important predictors. On the other hand, the amount of snowfall is considered the least important. </div> <br> <div align = "justify"> <a href = "https://archive.ics.uci.edu/ml/datasets/Seoul+Bike+Sharing+Demand">Source</a> of dataset. <b>Citations:</b> <ul> <li>Sathishkumar V E, Jangwoo Park, and Yongyun Cho. 'Using data mining techniques for bike sharing demand prediction in metropolitan city.' Computer Communications, Vol.153, pp.353-366, March, 2020 <li>Sathishkumar V E and Yongyun Cho. 'A rule-based model for Seoul Bike sharing demand prediction using weather data' European Journal of Remote Sensing, pp. 1-18, Feb, 2020 </ul> </div> <h2 id=disaster_learning_of_a_machine_learning_model ><a href="#disaster_learning_of_a_machine_learning_model" class=header-anchor >Disaster Learning of a Machine Learning Model</a></h2> <h4 id=15_september_2023_last_updated_22_september_2023 ><a href="#15_september_2023_last_updated_22_september_2023" class=header-anchor >15 September 2023 &#40;Last Updated: 22 September 2023&#41;</a></h4> <div align = "justify"> (The associated codes and implementations in this project is located in the Jupyter <a href = "/assets/titanic_xgb.ipynb">notebook</a>.) </div> <br> <div align = "justify"> Ahoy! Kaggle is hosting a titanic machine learning <a href = "https://www.kaggle.com/competitions/titanic">competition</a> where the goal is to classify whether a passenger survives or not. </div> <br> <div align = "justify"> For each passenger, the features include the following: <ol> <li>Ticket class <code>pclass</code>: <code>1</code> = 1st, <code>2</code> = 2nd, <code>3</code> = 3rd <li>Sex <code>sex</code> <li>Age in years <code>Age</code> <li>Number of siblings or spouses aboard <code>sibsp</code> <li>Number of parents or children aboard <code>parch</code> <li>Ticket Number <code>ticket</code> <li>Fare <code>fare</code> <li>Cabin Number <code>cabin</code> <li>Port of Embarkation <code>embarked</code> : <code>C</code> = Cherbourg, <code>Q</code> = Queenstown, <code>S</code> = Southampton <li>Passenger ID <code>PassengerId</code> <li>Passenger Name <code>name</code> </ol> </div> <br> <div align = "justify"> To start with the classification, we preprocess the dataset. We drop the <code>PassengerId</code>, the <code>ticket</code>, and the <code>name</code> columns as they contain unique values. We replace the <code>male</code> value to 0 and the <code>female</code> value to 1 in the <code>sex</code> column to contain numerical values. Observe that the columns <code>age</code>, <code>cabin</code>, and <code>embarked</code> are the columns with missing values. By setting a threshold of 30% for dropping features, we drop the <code>cabin</code> column. The mode is used to impute the categorical feature <code>embarked</code>, while the mean is used for the numerical feature <code>age</code>. In this case, mean imputation is justified since the ages are not highly skewed, as shown in the histogram below. Lastly, a one-hot encoder is implemented on the categorical variables <code>pclass</code> and <code>embarked</code> for training purposes. </div> <br> <div align = "center"> <img src="/assets/titanic_hist.png"> </div> <br> <div align = "justify"> None of the features are highly correlated to each other, as presented in the correlation heatmap below. However, the ages and the fares have high variances. Hence, we standardize those features by removing the mean and scaling to the unit variance. Next, we split the data where 75% comprises the training data. Now, we are ready for model training. </div> <br> <div align = "center"> <img src="/assets/titanic_heatmap.png"> </div> <br> <div align = "justify"> We choose among the logistic regression, the k-nearest neighbors (KNN), and the gradient-boosted decision tree (GBDT) models for binary classification. Note that decision trees are usually insensitive to scaling. This means that we can use the scaled data for fitting across all models. Logistic regression are intended for linear solutions while KNN are intended for non-linear solutions. All the models with default hyperparameters give an accuracy of around 75%. To improve the models, we employ stratified k-fold cross-validation and a randomized search cross-validation for hyperparameter tuning. Both the logistic regression and the KNN models produce an accuracy close to 85% while the GBDT model produce an accuracy of 88%. Although this is a slight advantage to the other models, we choose the GBDT model for the predictions. </div> <br> <div align=justify > The data for prediction has the same features. We preprocess the data similar to the previous data. However, in this case, the <code>fare</code> column has a null value. For this feature, we impute with the median since the data is right-skewed, as shown in the histogram below. Afterwards, the similar steps follow until the fitting of data into the chosen model. We predict the survivability of the passengers and save the results as a comma-separated values (CSV) <a href = "/assets/gender_submission.csv">file</a> for submission. Upon submisison, Kaggle reveals that the predictions are 77.2% accurate. </div> <br> <div align = "center"> <img src="/assets/titanic_test_hist_fare.png"> </div> <div align=justify > We also utilized the automated marchine learning package <a href = "https://github.com/EpistasisLab/tpot/">TPOT</a>. This package enables one to find an ML model that works well for the cleaned data. In this case, we use it to find a non-deep learning model. After execution, the best pipeline found is also an GBDT model with Gini impurity for splitting the nodes. The predictions are different from the previously generated predictions but has the same accuracy score. </div> <div align = "center"> <code>XGBClassifier(ZeroCount(SelectFwe(DecisionTreeClassifier(input_matrix, criterion=gini, max_depth=5, min_samples_leaf=4, min_samples_split=9), alpha=0.007)), learning_rate=0.5, max_depth=5, min_child_weight=16, n_estimators=100, n_jobs=1, subsample=0.7000000000000001, verbosity=0)</code> </div> <h2 id=dance-themed_playlist_creation_using_cluster_analysis ><a href="#dance-themed_playlist_creation_using_cluster_analysis" class=header-anchor >Dance-Themed Playlist Creation using Cluster Analysis</a></h2> <h4 id=21_september_2023_last_updated_26_september_2023 ><a href="#21_september_2023_last_updated_26_september_2023" class=header-anchor >21 September 2023 &#40;Last Updated: 26 September 2023&#41;</a></h4> <div align = "justify"> (The associated codes and implementations in this project is located in the Jupyter <a href = "/assets/spotify_cluster.ipynb">notebook</a>.) </div> <br> <div align = "justify"> <h2>Background</h2> While summer already ended here in the Philippines, temperatures turn up for those in the Northern Hemisphere. There is no better time than now to hold pool and beach parties. In sync with this plans, the company has decided to host a dance party. A <a href = "/assets/spotify_cluster.csv">list</a> of tracks containing one-hundred twenty five (125) genres of Spotify music tracks was collected, with each genre containing approximately one thousand (1000) tracks. Each row represents a track that has some audio features, such as danceability and valence, associated with it. The most recent song in the playlist is released on October 2022. </div> <br> <div align = "justify"> <h2>Objective</h2> We are tasked to curate a dance-themed playlist for the party in order to create an atmosphere that will let attendees dance their hearts out. </div> <br> <div align = "justify"> <h3>Data Preprocessing</h3> To create a dance-themed playlist, a <b>cluster analysis</b> may be employed to allow grouping of 'similar' tracks. Before implementing clustering, we start by importing data as a dataframe using the <code>pandas</code> library and cleaning the data, if needed. First, we drop rows with duplicate values across all features. Next, we drop rows with duplicates on the `track_id` column as tracks have unique identifications. Lastly, we drop rows with the same album name, track name, and set of artists. Note that album and track names are not subject to trademark while an artist does. Observations with missing artists, album name, and track name are also dropped. This process is justified because we cannot add an unknown song even though its audio features are given. </div> <br> <div align = "justify"> <h3>Feature Engineering</h3> After cleaning the data, every track must associate to a unique id. Now, we can drop the `track_id` column. This process also saves memory storage. <br> One may argue to drop the `artists` column since artists may produce songs of different genres. Instead, the column may be replaced by the number of artists present. Observe that the artists are separated by semicolons (;). </div> <div align = "justify"> <h3>Dilemma</h3> The genre feature has one hundred fourteen (114) unique values. Some categories may classify into a single group but differences still occur. For examples, J-Pop and K-Pop may be considered as pop music but they have some differences. </div> <br> <div align = "justify"> <h3>Feature Selection</h3> For now, we will not consider the track genre and use the remaining audio features. Cluster analysis are usually applied to solely continuous or categorical variables. The reason is that using, for example, Euclidean distance in clustering makes no sense for categorical variables. Mixed-type data are more common nowadays and studies uses one-hot encoding to analyze the data. For this project, we analyze using solely continuous, solely categorical, and mixed types. </div> <br> <div align = "justify"> <h3>Multicollinearity</h3> To see correlation between the features, the heatmap corresponding to the correlation coefficients is shown below. None of the features are highly correlated to each other. Danceability and valence are moderately correlated. This correlation is justified since valence representative positiveness and more positive tracks are typically danceable songs. However, we intend not to remove valence since it still differs from the danceability score. </div> <br> <div align = "justify"> <h3>Anomaly Detection</h3> As shown from the boxplots, almost all features contains outliers or anomalies. </div> <br> <div align = "justify"> <h3>Model Selection</h3> We must choose clustering algorithms that are insensitive to outliers. Thus, either a density-based spatial clustering of applications with noise (DBSCAN) model or Guassian mixture models (GMM). GMM are characterized by high complexity and slow convergence. Hence, we can choose to implement DBSCAN. A closely related algorithm to DBSCAN is OPTICS. It is more suitable to large datasets than DBSCAN. </div> <br> <div align = "justify"> <h3>Playlist Creation</h3> By observing the mean (or median) of the danceability score among the tracks in each cluster, we choose the cluster with the highest scores. Moreover, assuming the dance party is for adults, we remove songs with a children or kids genre. Lastly, the dance-themed playlist is completed by filtering the top 50 songs based on danceability. </div> <h1 id=dashboards ><a href="#dashboards" class=header-anchor >DASHBOARDS</a></h1> <h2 id=listen_to_the_sound_of_a_dashboard_spotify_2023 ><a href="#listen_to_the_sound_of_a_dashboard_spotify_2023" class=header-anchor >Listen to the Sound of a Dashboard &#40;Spotify 2023&#41;</a></h2> <h4 id=16_september_2023_last_updated_18_september_2023 ><a href="#16_september_2023_last_updated_18_september_2023" class=header-anchor >16 September 2023 &#40;Last Updated: 18 September 2023&#41;</a></h4> <div align = "justify"> (The associated codes and implementations in this project is located in the Jupyter <a href = "/assets/moststreamedsongs.ipynb">notebook</a> and Power BI eXchange <a href = /assets/dashboard.pbix>file</a>.) </div> <br> <div align = "justify"> For this project, we use the <a href = "https://www.kaggle.com/datasets/nelgiriyewithana/top-spotify-songs-2023">dataset</a> found in Kaggle presenting the most streamed songs in the year 2023. We showcase some SQL and Power BI skills for personal purposes. First, the data is imported in Microsoft SQL Server Management Studio. The total number of tracks is nine-hundred fifty-three (953) with six-hundred fourty five (645) distinct artists or groups of artists. <div> <br> <div align = "justify"> Most of the tracks, specifically four-hundred two (402), are songs released in the year two thousand and twenty two (2022). In terms of age, the oldest track is Agudo Magico 3 by Stryx, utku INC, and Thezth released in 1930. On the other hand, the latest track is Seven by Jung Kook featuring Latto released on 14 July 2023. In terms of the number of tracks, Taylor Swift has the highest numbers of songs in the dataset with thirty-four (34) songs followed by The Weekend with twenty-two (22) songs. </div> <br> <div align = "justify"> Now, we examine the songs for the past five years. There are seven hundred sixty-nine (769) tracks mostly comprised of tracks released in 2022. In this five-year window, the tracks 'As It Was' and 'Blinding Lights' by the Weekend, are the two of the top ten songs in terms of the number of streams. Non-instrumental songs with a high danceability factor are the most streamed are preferred by listeners. The average beats per minute (bpm) is approaximately one hundred twenty-two (122), which is near the <a href = "https://www.masterclass.com/articles/how-to-find-the-bpm-of-a-song">perfect tempo considered to be a hit</a>, according to some songwriters. Lastly, as a fun observation that needs to be experimented, about fifteen percent (15%) of the songs are released in May. </div> <br> <div align = "justify"> <img src="/assets/dashboard2019-2023.png" align=top  width="95%"> </div> <h1 id=statistical_tests ><a href="#statistical_tests" class=header-anchor >STATISTICAL TESTS</a></h1> <h2 id=ab_testing ><a href="#ab_testing" class=header-anchor >A/B Testing</a></h2> <h4 id=28_august_2023_last_updated_4_september_2023 ><a href="#28_august_2023_last_updated_4_september_2023" class=header-anchor >28 August 2023 &#40;Last Updated: 4 September 2023&#41;</a></h4> <div align = "justify"> In this project, we conduct an A/B test using the <a href = "https://www.kaggle.com/datasets/sergylog/ab-test-useraggregated-results">Kaggle</a> data. We will use common statistical procedures outlined in the <a href = "https://vkteam.medium.com/practitioners-guide-to-statistical-tests-ed2d580ef04f#1e3b">Medium</a> article by the VK Team. Moreover, we will implement the test in Python. </div> <br> <div align = "justify"> First, we download the data saved in a CSV file and read the file using the pandas library. The data consists of the user ID, the number of views, the number of clicks, and the group where each user belongs from eighty-thousand (80,000) users. Please refer to the following table below to see the first five (5) observations. Note that the values in the column associated to the user ID are distinct. Hence, we can drop the column from the dataframe. </div> <br> <table> <tr> <th>user_id <th>group <th>views <th>clicks <tr> <td>1 <td>control <td>3.0 <td>0.0 <tr> <td>2 <td>control <td>1.0 <td>0.0 <tr> <td>3 <td>control <td>3.0 <td>1.0 <tr> <td>4 <td>control <td>5.0 <td>0.0 <tr> <td>5 <td>control <td>2.0 <td>0.0 </table> <br> <div align = "justify"> Then, we inspect for missing values and inconsistent data types in each column. Using the info function from pandas, there are no null values present. The number of views and clicks are stored as 64-bit double-precision values, which expends memory storage. The minimum value for both columns is 0, while the maximum values are 21 and 206 for clicks and views, respectively. Hence, to free some memory, we convert each number of clicks as an 8-bit signed integer and each number of views as a 16-bit signed integer. We can also store each group label as a categorical data. </div> <br> <div align = "justify"> We formulate a null and an alternative hypotheses for this statistical test. We choose the null hypothesis stating that "there is no significant difference between the groups" and the alternative hypothesis stating otherwise. </div> <br> <div align = "justify"> To estimate the smallest sample size needed for this experiment, we choose a significance level of 0.05, a statistical power of 0.8, an allocation ratio of 1, and a minimum detectable effect of 2%. For a two sample t-test concerned on the number of clicks, the smallest sample size needed is four thousand seven hundred twenty-one (4721). </div> <br> <div align = "justify"> To start with the hypothesis test, we check whether the assumptions of a t-test are satisfied or not. We can determine if the samples are normally distributed by looking at their histograms or quantile-quantile (Q-Q) plots. The following figures show the histogram for the number of clicks by the control group and the Q-Q plot for the number of clicks by the treatment group. </div> <div class=row > <div class=column > <img src="/assets/histogram.png" alt=Histogram  style="width:100%"> </div> <div class=column > <img src="/assets/qqplot.png" alt="Q-Q Plot" style="width:100%"> </div> </div> <div align = "justify"> Both the histogram and the Q-Q plot show that the samples are not normally distributed. Hence, we refrain from using the t-test for the hypothesis tesing. Instead, we can use the non-parametric Mann-Whitney U Test. Using this test, we obtain a p-value close to zero and less than the signifance level 0.05. Therefore, we can reject the null hypothesis and say that there is a significant difference between the models exposed to the control and the treatment groups. </div> <div align = "justify"> Now, we need to define a key metric to monitor for each group. We can compare the conversion rate defined by </div> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mi>C</mi><mo>=</mo><mfrac><mrow><munder><mo>∑</mo><mrow><mi>g</mi><mo>∈</mo><mi>G</mi></mrow></munder><msub><mi>c</mi><mi>g</mi></msub></mrow><mrow><munder><mo>∑</mo><mrow><mi>g</mi><mo>∈</mo><mi>G</mi></mrow></munder><msub><mi>v</mi><mi>g</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">C = \dfrac{\sum_{g \in G} c_g}{\sum_{g \in G} v_g}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:2.6976em;vertical-align:-1.1218em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.5758em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mop ><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.1786em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight">G</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.4358em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2861em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.8258em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mop ><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.1786em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight">G</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.4358em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal">c</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.1218em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span> <p>where <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span> denotes the group &#40;control or treatment&#41;, and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">c_g</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7167em;vertical-align:-0.2861em;"></span><span class=mord ><span class="mord mathnormal">c</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> is the number of clicks and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">v_g</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7167em;vertical-align:-0.2861em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> is the number of views for user <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo>∈</mo><mi>G</mi></mrow><annotation encoding="application/x-tex">g \in G</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7335em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >∈</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span>.</p> <p>&#40;TO BE CONTINUED&#41;</p> <h1 id=web_scraping ><a href="#web_scraping" class=header-anchor >WEB SCRAPING</a></h1> <h2 id=scrape_the_malt_extract_from_your_beer ><a href="#scrape_the_malt_extract_from_your_beer" class=header-anchor >Scrape the Malt Extract from Your Beer</a></h2> <h4 id=22_august_2023 ><a href="#22_august_2023" class=header-anchor >22 AUGUST 2023</a></h4> <div align=justify > In this project, we scrape data from the beer section of the <a href = "https://www.boozy.ph">Boozy</a> website using the Beautiful Soup library in Python. Specifically, for each product in the said section, we extract the following: <ul> <li> Name <li> Price <li> Star Rating <li> Number of Reviews </ul> </div> <div align=justify > A screenshot of the first page in the beer section of the website is shown below. </div> <div align=center > <br> <img src="/assets/BeerRow.png" align=top  width="90%"> <br> </div> <div align=justify > The program for data scraping is shown in the Python file named <a href = "/assets/scraper.py">scraper</a>. In this implementation, we construct a Pandas dataframe where names are stored as string, prices and ratings as floating point numbers, and number of reviews as integers. In the following figure, we see the first five observations. Prices are in Philippines pesos while ratings are on an integer scale of 1 to 5 where 1 is the lowest and 5 is the highest. </div> <br> <table> <tr> <th>Name <th>Price <th>Rating <th>No. of Reviews <tr> <td>Engkanto Mango Nation - Hazy IPA 330mL Bottle ... <td>543.0 <td>5.0 <td>2 <tr> <td>Engkanto High Hive - Honey Ale 330mL Bottle 4-... <td>407.0 <td>4.0 <td>5 <tr> <td>Engkanto Green Lava - Double IPA 330mL Bottle ... <td>594.0 <td>5.0 <td>1 <tr> <td>Engkanto Live It Up! Lager 330mL Bottle 4-Pack <td>407.0 <td>5.0 <td>1 <tr> <td>Engkanto Paint Me Purple - Ube Lager 330mL Bot... <td>543.0 <td>5 <td>1 </table> <div align=justify > As a web scraping project, we focused less on producing data mainly used for data analysis. However, we can provide some information about the products. We start by considering the prices. The cheapest beer products priced at 60 pesos are the 330 mL bottled and the 330mL canned versions of Tiger Crystal. On the other hand, the most expensive beer product is the Stella Artois 330mL Bottle Bundle of 24 priced at 3576 pesos. Next, we consider the ratings. The five beer products with the highest number of reviews are shown in the following table. The number of reviews is also indicated in the table. </div> <br> <table> <tr> <th>Name <th>Reviews <tr> <td>Heineken 330mL 6-Pack <td>99 <tr> <td>Crazy Carabao Variety Pack #1 <td>42 <tr> <td>Hoegaarden Rosee 750mL <td>41 <tr> <td>San Miguel Pale Pilsen 330mL Can 6-Pack <td>33 <tr> <td>Crazy Carabao IPA 330mL Bottle 6-Pack <td>31 </table> <div align=justify > Now, we consider the star ratings. There are 77 products with a star rating of 5. We can filter this data further by including the number of reviews. The four highest-rated beer products with at least 5 reviews are presented in the following table, including their rating and number of reviews. </div> <br> <table> <tr> <th>Name <th>Rating <th>Reviews <tr> <td>Pilsner Urquell 330mL Bottle Pack of 6 <td>5.0 <td>12 <tr> <td>Sapporo 330mL Bundle of 6 <td>5.0 <td>12 <tr> <td>Stella Artois 330mL Bottle Bundle of 6 <td>5.0 <td>11 <tr> <td>Paulaner Weissbier Dunkel 500mL Bottle <td>5.0 <td>11 </table> <div align=justify > Moreover, the four lowest-rated beer products are shown in the following table. </div> <br> <table> <tr> <th>Name <th>Rating <th>Reviews <tr> <td>Rochefort 8 330mL <td>3.0 <td>1 <tr> <td>Royal Dutch Ultra Strong 14% 500mL <td>3.5 <td>2 <tr> <td>Tiger Crystal 330mL Can <td>3.8 <td>5 <tr> <td>Paulaner Weissbier Party Keg 5L <td>3.8 <td>5 </table> <h1 id=future_projects ><a href="#future_projects" class=header-anchor >FUTURE PROJECTS</a></h1> <h2 id=machine_unlearning ><a href="#machine_unlearning" class=header-anchor >Machine Unlearning</a></h2> <h2 id=topological_image_processing ><a href="#topological_image_processing" class=header-anchor >Topological Image Processing</a></h2> <h2 id=agricultural_topological_data_analysis ><a href="#agricultural_topological_data_analysis" class=header-anchor >Agricultural Topological Data Analysis</a></h2> <h2 id=sports_analytics_using_topological_data_analysis ><a href="#sports_analytics_using_topological_data_analysis" class=header-anchor >Sports Analytics using Topological Data Analysis</a></h2> <div class=page-foot > <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> Septimia Zenobia. Last modified: September 26, 2023. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div>